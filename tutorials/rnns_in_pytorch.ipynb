{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Sophie Katz\n",
    "#\n",
    "# This file is part of Sophie's ML Monorepo.\n",
    "#\n",
    "# Sophie's ML Monorepo is free software: you can redistribute it and/or modify it under\n",
    "# the terms of the GNU General Public License as published by the Free Software\n",
    "# Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "#\n",
    "# Sophie's ML Monorepo is distributed in the hope that it will be useful, but WITHOUT\n",
    "# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\n",
    "# PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License along with Sophie's\n",
    "# ML Monorepo. If not, see <https://www.gnu.org/licenses/>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch RNN Tutorial - Name Classification Using A Recurrent Neural Net\n",
    "\n",
    "Tutorial URL: https://www.youtube.com/watch?v=WEV61GmmPrk\n",
    "\n",
    "Valid as of: 2023.05.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.core.download import download_http\n",
    "from ml.core.extract import extract_archive\n",
    "from ml.core.repo_paths import get_dir_artifacts_data_raw, get_dir_artifacts_data_intermediate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'https://download.pytorch.org/tutorial/data.zip' to c:\\Users\\sophi\\Code\\ml\\artifacts\\data\\pytorch_rnn\\raw\\data.zip...\n",
      "  File already downloaded.\n",
      "Extracting c:\\Users\\sophi\\Code\\ml\\artifacts\\data\\pytorch_rnn\\raw\\data.zip to c:\\Users\\sophi\\Code\\ml\\artifacts\\data\\pytorch_rnn\\intermediate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.71M/9.71M [00:00<00:00, 2.40GB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extraction complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_dir_artifacts_data_raw = get_dir_artifacts_data_raw(\"pytorch_rnn\", create=True)\n",
    "path_dir_artifacts_data_intermediate = get_dir_artifacts_data_intermediate(\"pytorch_rnn\", create=True)\n",
    "\n",
    "path_data = path_dir_artifacts_data_raw / \"data.zip\"\n",
    "\n",
    "download_http(\"https://download.pytorch.org/tutorial/data.zip\", path_data)\n",
    "\n",
    "extract_archive(path_data, path_dir_artifacts_data_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [('Arabic', 'Khoury'), ('Arabic', 'Nahas'), ('Arabic', 'Daher'), ('Arabic', 'Gerges'), ('Arabic', 'Nazari'), ('Arabic', 'Maalouf'), ('Arabic', 'Gerges'), ('Arabic', 'Naifeh'), ('Arabic', 'Guirguis'), ('Arabic', 'Baba'), ('Arabic', 'Sabbagh'), ('Arabic', 'Attia'), ('Arabic', 'Tahan'), ('Arabic', 'Haddad'), ('Arabic', 'Aswad')]\n",
      "Countries: {0: 'Polish', 1: 'Chinese', 2: 'Japanese', 3: 'Dutch', 4: 'German', 5: 'Scottish', 6: 'French', 7: 'English', 8: 'Italian', 9: 'Russian', 10: 'Portuguese', 11: 'Vietnamese', 12: 'Korean', 13: 'Irish', 14: 'Czech', 15: 'Spanish', 16: 'Greek', 17: 'Arabic'}\n",
      "Alphabet: {'J', 'D', 'm', 'Y', 'E', 'v', 'V', 'e', 'y', 'F', 'Z', 'r', 'M', 'A', 'Q', 'x', 'I', 'C', 'K', 'a', 'g', 'O', 'z', 'B', '/', 'G', 'ł', 'R', 'i', 'L', '\\xa0', 't', 'n', 'c', 'o', \"'\", 'u', 'W', 'd', 'P', 's', 'q', 'f', 'p', ':', ' ', 'X', 'w', 'T', 'h', '-', '1', 'k', 'U', 'j', ',', 'N', 'S', 'b', 'ß', 'l', 'H'} (len: 62)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_ascii(text):\n",
    "    # Convert special characters to their ascii equivalents\n",
    "    return \"\".join([c for c in unicodedata.normalize(\"NFD\", text) if unicodedata.category(c) != \"Mn\"])\n",
    "\n",
    "def load_data(path):\n",
    "    dir_names = pathlib.Path(path, \"data\", \"names\")\n",
    "    result = []\n",
    "\n",
    "    for list_filename in os.listdir(dir_names):\n",
    "        country = list_filename.split(\".\")[0]\n",
    "\n",
    "        with open(dir_names / list_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            for name in file.readlines():\n",
    "                result.append((country, convert_to_ascii(name.strip())))\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_country_name_mapping(data):\n",
    "    return {key: value for key, value in enumerate(set([country for country, _ in data]))}\n",
    "\n",
    "def get_alphabet(data):\n",
    "    return set([c for _, name in data for c in name])\n",
    "\n",
    "data = load_data(path_dir_artifacts_data_intermediate)\n",
    "\n",
    "print(f\"Data: {data[:15]}\")\n",
    "\n",
    "country_name_mapping = get_country_name_mapping(data)\n",
    "\n",
    "print(f\"Countries: {country_name_mapping}\")\n",
    "\n",
    "assert len(country_name_mapping) == 18\n",
    "\n",
    "alphabet = get_alphabet(data)\n",
    "\n",
    "print(f\"Alphabet: {alphabet} (len: {len(alphabet)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_to_hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_to_output = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = T.cat((input, hidden), 1)\n",
    "        hidden = self.input_to_hidden(combined)\n",
    "        output = self.input_to_output(combined)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def create_hidden_initial(self):\n",
    "        return T.zeros(1, self.hidden_size)\n",
    "\n",
    "hidden_size = 128\n",
    "\n",
    "rnn = RNN(len(alphabet), hidden_size, len(country_name_mapping))\n",
    "\n",
    "hidden = rnn.create_hidden_initial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
